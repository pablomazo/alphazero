{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import namedtuple\n",
    "from random import random\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MCTS import MCTS\n",
    "from Node import Node\n",
    "from Game import TicTacToe_Board\n",
    "from ReplayMemory import ReplayMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare NN of policy:\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(9, 20)\n",
    "        self.l2 = nn.Linear(20, 9)\n",
    "        self.l3 = nn.Linear(20,1)\n",
    "        self.sm = nn.Softmax(dim=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x1 = self.l2(x) # Logit value of policy\n",
    "        x1 = self.sm(x1)\n",
    "        x2 = torch.tanh(self.l3(x)) # Value head.\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "-1\n",
      "-------------\n",
      "| o |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "1\n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "-1\n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "| o |   |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "1\n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "-1\n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "| o |   | x | \n",
      "-------------\n",
      "| o | x |   | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "#MCTS game:\n",
    "T = 0.3\n",
    "state = torch.tensor([0,0,0,0,0,0,0,0,0],dtype=torch.float)\n",
    "end = False\n",
    "player = -1\n",
    "\n",
    "dnn = DNN()\n",
    "game = TicTacToe_Board()\n",
    "root = Node(state, 1, player)\n",
    "mcts = MCTS(game, root, dnn)\n",
    "\n",
    "node = root\n",
    "while not end:\n",
    "    mcts.explore(node)\n",
    "    a = mcts.play(node, T)\n",
    "    node = node.children[a]\n",
    "    print(node.player)\n",
    "    game.plot(node.state)\n",
    "    \n",
    "    end, winner = game.check_end(node.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "\n",
    "\n",
    "def loss_plot(loss):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Loss')\n",
    "    loss = np.array(loss)\n",
    "    plt.plot(loss[:,0], loss[:,1])\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPACITY = 1000\n",
    "REPLAY_START_SIZE = 100\n",
    "BATCH = 100\n",
    "\n",
    "EPISODES = 1000\n",
    "\n",
    "NGAMES=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',('state', 'policy', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = DNN()\n",
    "replay_memory = ReplayMemory(CAPACITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(z, v, policy, net_pol):\n",
    "    a = torch.mean(torch.pow(z-v,2))\n",
    "    b = (policy * torch.log(net_pol)).sum()\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(dnn.parameters(), lr=1e-2, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(model, optimizer, loss_fn, memory):\n",
    "    if memory.__len__() < REPLAY_START_SIZE:\n",
    "        return\n",
    "    \n",
    "    transitions = memory.sample(BATCH)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    states = torch.cat(batch.state).reshape([BATCH,-1])\n",
    "    policy = torch.cat(batch.policy).reshape([BATCH,-1])\n",
    "    z = torch.cat(batch.reward).reshape([BATCH,-1])\n",
    "    \n",
    "    net_pol, v = dnn(states)\n",
    "    \n",
    "    \n",
    "    loss = loss_fn(z,v,policy,net_pol)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop:\n",
    "def play_game():\n",
    "    T = 0.3\n",
    "    state = torch.tensor([0,0,0,0,0,0,0,0,0],dtype=torch.float)\n",
    "    end = False\n",
    "    player = -1\n",
    "    \n",
    "    \n",
    "    game = TicTacToe_Board()\n",
    "    root = Node(state, 1, player)\n",
    "    mcts = MCTS(game, root, dnn, ngames=NGAMES)\n",
    "    \n",
    "    node = root\n",
    "    \n",
    "    history = []\n",
    "    while not end:\n",
    "        history.append(node)\n",
    "        mcts.explore(node)\n",
    "        a = mcts.play(node, T)\n",
    "        node = node.children[a]\n",
    "        \n",
    "        end, winner = game.check_end(node.state)\n",
    "    \n",
    "    # Save play in replaymemory\n",
    "    for node in history:\n",
    "        policy = torch.tensor([0,0,0,0,0,0,0,0,0],dtype=torch.float)\n",
    "        p = mcts.eval_policy(node, 1)\n",
    "        for i, a in enumerate(game.avail_actions(node.state)):\n",
    "            policy[a] = p[i]\n",
    "            \n",
    "        replay_memory.add(node.state, policy, torch.tensor([-winner*node.player], dtype=torch.float))\n",
    "        \n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_hist = []\n",
    "winner = []\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Episodes')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "plt.ion()\n",
    "for episode in range(EPISODES):\n",
    "    # Play game to fill memory\n",
    "    w = play_game()\n",
    "    winner.append([episode, w])\n",
    "    \n",
    "    # Optimize\n",
    "    for iopt in range(20):\n",
    "        loss = optimize(dnn, optimizer, loss_fn, replay_memory)\n",
    "    loss_hist.append([episode, loss])\n",
    "    \n",
    "    if len(winner) > 10:\n",
    "        win_prob = sum(w[1] for w in winner[-10:]) / len(winner[-10:])\n",
    "        print('Win mean:', win_prob)\n",
    "    print('Loss:', loss)\n",
    "    loss_plot(loss_hist)\n",
    "    \n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f73ef449950>]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "winner = np.array(winner)\n",
    "\n",
    "plt.plot(winner[:,0], winner[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1.3749e-02, 1.2155e-05, 4.9972e-03, 7.9449e-07, 1.1551e-04, 9.8059e-01,\n",
      "        5.2985e-04, 4.3081e-06, 5.8526e-06], grad_fn=<SoftmaxBackward>), tensor([5.0433e-05], grad_fn=<TanhBackward>))\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "(tensor([1.4466e-03, 1.4406e-07, 2.2420e-06, 7.1025e-11, 9.9823e-01, 2.5911e-06,\n",
      "        3.1005e-04, 2.4823e-08, 8.8339e-06], grad_fn=<SoftmaxBackward>), tensor([8.8550e-06], grad_fn=<TanhBackward>))\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "(tensor([4.9501e-03, 2.1148e-04, 2.2442e-04, 1.3747e-07, 3.3115e-07, 1.5657e-08,\n",
      "        2.4574e-03, 3.1245e-06, 9.9215e-01], grad_fn=<SoftmaxBackward>), tensor([2.8234e-05], grad_fn=<TanhBackward>))\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "(tensor([6.5171e-05, 1.8541e-03, 8.9507e-01, 1.1315e-06, 8.6773e-10, 3.4337e-12,\n",
      "        1.0299e-01, 2.3266e-05, 1.8534e-07], grad_fn=<SoftmaxBackward>), tensor([-2.3611e-05], grad_fn=<TanhBackward>))\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "(tensor([1.1572e-05, 9.9837e-07, 3.6876e-07, 8.4487e-09, 2.3620e-12, 9.6329e-10,\n",
      "        9.9999e-01, 1.0379e-07, 9.8628e-13], grad_fn=<SoftmaxBackward>), tensor([-5.6572e-05], grad_fn=<TanhBackward>))\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x |   | x | \n",
      "-------------\n",
      "(tensor([2.3685e-04, 1.5563e-02, 7.7358e-06, 2.1756e-03, 1.6625e-10, 1.6445e-07,\n",
      "        2.9653e-08, 9.8202e-01, 3.3123e-12], grad_fn=<SoftmaxBackward>), tensor([7.0419e-05], grad_fn=<TanhBackward>))\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "(tensor([1.5470e-04, 9.9980e-01, 2.1171e-08, 2.1484e-05, 3.5190e-09, 8.6873e-10,\n",
      "        2.6724e-07, 2.4234e-05, 9.0608e-10], grad_fn=<SoftmaxBackward>), tensor([-4.2841e-06], grad_fn=<TanhBackward>))\n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "(tensor([2.1302e-03, 1.5305e-07, 2.9729e-06, 9.9784e-01, 5.6262e-09, 4.0193e-08,\n",
      "        7.3711e-06, 1.8082e-05, 2.0377e-07], grad_fn=<SoftmaxBackward>), tensor([5.4475e-05], grad_fn=<TanhBackward>))\n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "(tensor([9.9987e-01, 1.7186e-09, 8.5495e-07, 1.1212e-04, 3.7552e-06, 2.6084e-09,\n",
      "        1.4553e-05, 7.7378e-07, 2.1688e-07], grad_fn=<SoftmaxBackward>), tensor([-3.3941e-05], grad_fn=<TanhBackward>))\n",
      "-------------\n",
      "| x | x | o | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "#Test:\n",
    "state = torch.tensor([0,0,0,0,0,0,0,0,0],dtype=torch.float)\n",
    "end = False\n",
    "player = -1\n",
    "\n",
    "game = TicTacToe_Board()\n",
    "root = Node(state, 1, player)\n",
    "mcts = MCTS(game, root, dnn)\n",
    "\n",
    "node = root\n",
    "while not end:\n",
    "    # Expand state:\n",
    "    mcts.player *= -1\n",
    "    actions = game.avail_actions(node.state)\n",
    "    mcts.expand(node, actions)\n",
    "    a = torch.argmax(torch.tensor([child.P for child in node.children]))\n",
    "    print(dnn(node.state))\n",
    "    node = node.children[a]\n",
    "    game.plot(node.state)\n",
    "    \n",
    "    end, winner = game.check_end(node.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "| x | x |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| o |   |   | \n",
      "-------------\n",
      "tensor(5) (tensor([6.7941e-04, 3.8145e-03, 4.4504e-03, 1.5902e-03, 1.4563e-04, 9.8577e-01,\n",
      "        5.8544e-09, 1.6703e-03, 1.8838e-03]), tensor([0.2423]))\n"
     ]
    }
   ],
   "source": [
    "state = torch.tensor([1,1,0,0,0,0,-1,0,0],dtype=torch.float)\n",
    "game.plot(state)\n",
    "with torch.no_grad():\n",
    "    policy = dnn(-state)\n",
    "print(torch.argmax(policy[0]), policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "| x | x |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| o |   |   | \n",
      "-------------\n",
      "tensor(5) (tensor([4.2972e-04, 3.3410e-03, 1.8668e-01, 5.0187e-03, 4.2102e-05, 7.8348e-01,\n",
      "        6.1674e-07, 8.0598e-03, 1.2950e-02]), tensor([-0.0011]))\n"
     ]
    }
   ],
   "source": [
    "state = torch.tensor([1,1,0,0,0,0,-1,0,0],dtype=torch.float)\n",
    "game.plot(state)\n",
    "with torch.no_grad():\n",
    "    policy = dnn(state)\n",
    "print(torch.argmax(policy[0]), policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "tensor([0.0204, 0.0000, 0.0000, 0.0000, 0.0000, 0.9796, 0.0000, 0.0000, 0.0000]) 0.0\n",
      "(tensor([1.3749e-02, 1.2155e-05, 4.9972e-03, 7.9449e-07, 1.1551e-04, 9.8059e-01,\n",
      "        5.2985e-04, 4.3081e-06, 5.8526e-06]), tensor([5.0433e-05]))\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "tensor([0.0103, 0.0000, 0.0000, 0.0000, 0.9897, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([0.0239])\n",
      "(tensor([1.4466e-03, 1.4406e-07, 2.2420e-06, 7.1025e-11, 9.9823e-01, 2.5911e-06,\n",
      "        3.1005e-04, 2.4823e-08, 8.8339e-06]), tensor([8.8550e-06]))\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "tensor([0.0069, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9931]) tensor([-0.0112])\n",
      "(tensor([4.9501e-03, 2.1148e-04, 2.2442e-04, 1.3747e-07, 3.3115e-07, 1.5657e-08,\n",
      "        2.4574e-03, 3.1245e-06, 9.9215e-01]), tensor([2.8234e-05]))\n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "tensor([0.0052, 0.0000, 0.9793, 0.0000, 0.0000, 0.0000, 0.0155, 0.0000, 0.0000]) tensor([0.0075])\n",
      "(tensor([6.5171e-05, 1.8541e-03, 8.9507e-01, 1.1315e-06, 8.6773e-10, 3.4337e-12,\n",
      "        1.0299e-01, 2.3266e-05, 1.8534e-07]), tensor([-2.3611e-05]))\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "|   |   | x | \n",
      "-------------\n",
      "tensor([0.0042, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9958, 0.0000, 0.0000]) tensor([-0.0002])\n",
      "(tensor([1.1572e-05, 9.9837e-07, 3.6876e-07, 8.4487e-09, 2.3620e-12, 9.6329e-10,\n",
      "        9.9999e-01, 1.0379e-07, 9.8628e-13]), tensor([-5.6572e-05]))\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x |   | x | \n",
      "-------------\n",
      "tensor([0.0035, 0.0105, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9860, 0.0000]) tensor([0.0045])\n",
      "(tensor([2.3685e-04, 1.5563e-02, 7.7358e-06, 2.1756e-03, 1.6625e-10, 1.6445e-07,\n",
      "        2.9653e-08, 9.8202e-01, 3.3123e-12]), tensor([7.0419e-05]))\n",
      "-------------\n",
      "|   |   | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "tensor([0.0030, 0.9970, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([-6.0137e-05])\n",
      "(tensor([1.5470e-04, 9.9980e-01, 2.1171e-08, 2.1484e-05, 3.5190e-09, 8.6873e-10,\n",
      "        2.6724e-07, 2.4234e-05, 9.0608e-10]), tensor([-4.2841e-06]))\n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "|   | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "tensor([0.0026, 0.0000, 0.0000, 0.9974, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]) tensor([7.7222e-05])\n",
      "(tensor([2.1302e-03, 1.5305e-07, 2.9729e-06, 9.9784e-01, 5.6262e-09, 4.0193e-08,\n",
      "        7.3711e-06, 1.8082e-05, 2.0377e-07]), tensor([5.4475e-05]))\n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0.]) tensor([8.9791e-08])\n",
      "(tensor([9.9987e-01, 1.7186e-09, 8.5495e-07, 1.1212e-04, 3.7552e-06, 2.6084e-09,\n",
      "        1.4553e-05, 7.7378e-07, 2.1688e-07]), tensor([-3.3941e-05]))\n"
     ]
    }
   ],
   "source": [
    "T = 0.3\n",
    "state = torch.tensor([0,0,0,0,0,0,0,0,0],dtype=torch.float)\n",
    "end = False\n",
    "player = -1\n",
    "\n",
    "\n",
    "game = TicTacToe_Board()\n",
    "root = Node(state, 1, player)\n",
    "mcts = MCTS(game, root, dnn, ngames=NGAMES)\n",
    "\n",
    "node = root\n",
    "\n",
    "history = []\n",
    "while not end:\n",
    "    history.append(node)\n",
    "    mcts.explore(node)\n",
    "    a = mcts.play(node, T)\n",
    "    node = node.children[a]\n",
    "    \n",
    "    end, winner = game.check_end(node.state)\n",
    "\n",
    "# Save play in replaymemory\n",
    "for node in history:\n",
    "    policy = torch.tensor([0,0,0,0,0,0,0,0,0],dtype=torch.float)\n",
    "    p = mcts.eval_policy(node, 1)\n",
    "    for i, a in enumerate(game.avail_actions(node.state)):\n",
    "        policy[a] = p[i]\n",
    "        \n",
    "    game.plot(node.state)\n",
    "    print(policy, node.Q)\n",
    "    with torch.no_grad():\n",
    "        print(dnn(node.state))\n",
    "    \n",
    "    replay_memory.add(node.state, policy, torch.tensor([-winner*node.player], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "|   | x | o | \n",
      "-------------\n",
      "tensor([ 1., -1.,  1., -1., -1.,  1.,  0.,  1., -1.])\n"
     ]
    }
   ],
   "source": [
    "#Test:\n",
    "state = torch.tensor([ 1., -1.,  1., -1., -1.,  1,  0.,  1.,  0.],dtype=torch.float)\n",
    "end = False\n",
    "player = 1\n",
    "\n",
    "game = TicTacToe_Board()\n",
    "root = Node(state, 1, player)\n",
    "mcts = MCTS(game, root, dnn)\n",
    "\n",
    "game.plot(state)\n",
    "node = root\n",
    "# Expand state:\n",
    "mcts.player *= -1\n",
    "actions = game.avail_actions(node.state)\n",
    "mcts.expand(node, actions)\n",
    "a = torch.argmax(torch.tensor([child.P for child in node.children]))\n",
    "node = node.children[a]\n",
    "game.plot(node.state)\n",
    "\n",
    "end, winner = game.check_end(node.state)\n",
    "print(node.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
