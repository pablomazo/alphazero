{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import namedtuple\n",
    "from random import random\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MCTS import MCTS\n",
    "from Node import Node\n",
    "from Game import Connect4\n",
    "from ReplayMemory import ReplayMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare NN of policy:\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(42, 20)\n",
    "        self.l2 = nn.Linear(20, 7)\n",
    "        self.l3 = nn.Linear(20,1)\n",
    "        self.sm = nn.Softmax(dim=0)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x.view(-1)))\n",
    "        x1 = self.l2(x) # Logit value of policy\n",
    "        x1 = self.sm(x1)\n",
    "        x2 = torch.tanh(self.l3(x)) # Value head.\n",
    "        return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   | x |   |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   | x |   |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "-----------------------------\n",
      "|   |   |   | x | x |   |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "-----------------------------\n",
      "|   | o |   | x | x |   |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x |   |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   | o |   |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   | o | x |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   | o |   |   | o | x |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   | x |   | \n",
      "-----------------------------\n",
      "|   | o |   |   | o | x |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   | x |   | \n",
      "-----------------------------\n",
      "|   | o | o |   | o | x |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   | x |   | \n",
      "-----------------------------\n",
      "|   | o | o | x | o | x |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   | o |   | x |   | \n",
      "-----------------------------\n",
      "|   | o | o | x | o | x |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   | x |   | \n",
      "-----------------------------\n",
      "|   |   |   | o |   | x |   | \n",
      "-----------------------------\n",
      "|   | o | o | x | o | x |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   | o |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   | x |   | \n",
      "-----------------------------\n",
      "|   |   |   | o |   | x |   | \n",
      "-----------------------------\n",
      "|   | o | o | x | o | x |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n",
      "-----------------------------\n",
      "|   |   |   |   |   |   |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   | o |   | \n",
      "-----------------------------\n",
      "|   |   |   |   |   | x |   | \n",
      "-----------------------------\n",
      "|   |   |   | o | x | x |   | \n",
      "-----------------------------\n",
      "|   | o | o | x | o | x |   | \n",
      "-----------------------------\n",
      "|   | o | x | x | x | o |   | \n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "#MCTS game:\n",
    "T = 0.3\n",
    "state = torch.zeros(6,7, dtype=torch.float)\n",
    "end = False\n",
    "player = -1\n",
    "\n",
    "dnn = DNN()\n",
    "game = Connect4()\n",
    "root = Node(state, 1, player)\n",
    "mcts = MCTS(game, root, dnn, ngames=200)\n",
    "\n",
    "node = root\n",
    "while not end:\n",
    "    mcts.explore(node)\n",
    "    a = mcts.play(node, T)\n",
    "    node = node.children[a]\n",
    "    game.plot(node.state)\n",
    "    \n",
    "    end, winner = game.check_end(node.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "def loss_plot(loss):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Loss')\n",
    "    loss = np.array(loss)\n",
    "    plt.plot(loss[:,0], loss[:,1])\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPACITY = 5000\n",
    "REPLAY_START_SIZE = 100\n",
    "BATCH = 100\n",
    "\n",
    "EPISODES = 1000\n",
    "\n",
    "NGAMES=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',('state', 'policy', 'reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn = DNN()\n",
    "replay_memory = ReplayMemory(CAPACITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(z, v, policy, net_pol):\n",
    "    a = torch.mean(torch.pow(z-v,2))\n",
    "    b = (policy * torch.log(net_pol)).sum()\n",
    "    return a - b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(dnn.parameters(), lr=1e-2, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(model, optimizer, loss_fn, memory):\n",
    "    if memory.__len__() < REPLAY_START_SIZE:\n",
    "        return\n",
    "    \n",
    "    transitions = memory.sample(BATCH)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "    \n",
    "    states = torch.cat(batch.state).reshape([BATCH,-1])\n",
    "    policy = torch.cat(batch.policy).reshape([BATCH,-1])\n",
    "    z = torch.cat(batch.reward).reshape([BATCH,-1])\n",
    "    \n",
    "    net_pol, v = dnn(states)\n",
    "    \n",
    "    \n",
    "    loss = loss_fn(z,v,policy,net_pol)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop:\n",
    "def play_game():\n",
    "    T = 0.3\n",
    "    state = torch.tensor([0,0,0,0,0,0,0,0,0],dtype=torch.float)\n",
    "    end = False\n",
    "    player = -1\n",
    "    \n",
    "    \n",
    "    game = Connect4()\n",
    "    root = Node(state, 1, player)\n",
    "    mcts = MCTS(game, root, dnn, ngames=NGAMES)\n",
    "    \n",
    "    node = root\n",
    "    \n",
    "    history = []\n",
    "    while not end:\n",
    "        history.append(node)\n",
    "        mcts.explore(node)\n",
    "        a = mcts.play(node, T)\n",
    "        node = node.children[a]\n",
    "        \n",
    "        end, winner = game.check_end(node.state)\n",
    "    \n",
    "    # Save play in replaymemory\n",
    "    for node in history:\n",
    "        policy = torch.tensor([0,0,0,0,0,0,0,0,0],dtype=torch.float)\n",
    "        p = mcts.eval_policy(node, 1)\n",
    "        for i, a in enumerate(game.avail_actions(node.state)):\n",
    "            policy[a] = p[i]\n",
    "            \n",
    "        replay_memory.add(node.state, policy, torch.tensor([-winner*node.player], dtype=torch.float))\n",
    "        \n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0f51b8a0a47e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPISODES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Play game to fill memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplay_game\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mwinner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-52d75fd2c486>\u001b[0m in \u001b[0;36mplay_game\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmcts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Proyectos/ML_Projects/alphazero/MCTS.py\u001b[0m in \u001b[0;36mexplore\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0migame\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Proyectos/ML_Projects/alphazero/MCTS.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, root)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0;31m# Expand node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                 \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavail_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Proyectos/ML_Projects/alphazero/Connect4/Game.py\u001b[0m in \u001b[0;36mavail_actions\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_hist = []\n",
    "winner = []\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('Episodes')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "plt.ion()\n",
    "for episode in range(EPISODES):\n",
    "    # Play game to fill memory\n",
    "    w = play_game()\n",
    "    winner.append([episode, w])\n",
    "    \n",
    "    # Optimize\n",
    "    for iopt in range(20):\n",
    "        loss = optimize(dnn, optimizer, loss_fn, replay_memory)\n",
    "    loss_hist.append([episode, loss])\n",
    "    \n",
    "    if len(winner) > 10:\n",
    "        win_prob = sum(w[1] for w in winner[-10:]) / len(winner[-10:])\n",
    "        print('Win mean:', win_prob)\n",
    "    print('Loss:', loss)\n",
    "    loss_plot(loss_hist)\n",
    "    \n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " Save model to file:\n",
    "torch.save(dnn.state_dict(), './TicTacToe_Agent.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = np.array(loss_hist)\n",
    "winner_hist = np.array(winner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(10,4))\n",
    "\n",
    "ax[0].plot(loss_hist[:,0], loss_hist[:,1])\n",
    "ax[1].plot(winner_hist[:,0], winner_hist[:,1])\n",
    "\n",
    "ax[0].set_xlabel('Episode')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "\n",
    "ax[1].set_xlabel('Episode')\n",
    "ax[1].set_ylabel('Win mean')\n",
    "\n",
    "plt.savefig('loss_wins.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:\n",
    "state = torch.tensor([ 1., -1.,  1., -1., 1.,  1,  0.,  -1.,  0.],dtype=torch.float)\n",
    "end = False\n",
    "player = 1\n",
    "\n",
    "game = TicTacToe_Board()\n",
    "root = Node(state, 1, player)\n",
    "mcts = MCTS(game, root, dnn)\n",
    "\n",
    "game.plot(state)\n",
    "node = root\n",
    "# Expand state:\n",
    "mcts.player *= -1\n",
    "actions = game.avail_actions(node.state)\n",
    "mcts.expand(node, actions)\n",
    "a = torch.argmax(torch.tensor([child.P for child in node.children]))\n",
    "node = node.children[a]\n",
    "game.plot(node.state)\n",
    "print(node.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,0,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
